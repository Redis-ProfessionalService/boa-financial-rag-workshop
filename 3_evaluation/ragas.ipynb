{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <div><img src=\"../assets/redis_logo.svg\" style=\"width: 130px\"> </div>\n",
    "    <div style=\"display: inline-block; text-align: center; margin-bottom: 10px;\">\n",
    "        <span style=\"font-size: 36px;\"><b>Evaluation with RAGAS</b></span>\n",
    "        <br />\n",
    "    </div>\n",
    "    <br />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating RAG\n",
    "\n",
    "The extent to which you can **evaluate** your system is the extent to which you can **improve** your system. Before going to prod, it is in your best interest to establish a framework for quickly and effectively understanding the quality of your RAG application. In this notebook, we will use the RAGAS framework, as proposed by [this paper](https://arxiv.org/pdf/2309.15217), to evaluate the RAG application developed in the previous examples. \n",
    "\n",
    "There is no substitute for reading the paper, but summarized below are the main metrics we will work with. Note: there are many more metrics that can be used depending on use case but these are the main ones covered in the paper so we will start there. \n",
    "\n",
    "# Quality metric breakdown\n",
    "\n",
    "The 3 quality metrics in the RAGAS framework are: **faithfulness**, **answer relevance**, and **context relevance**. Let's take a moment to define each and understand how we can arrive at their values.\n",
    "\n",
    "## Faithfulness\n",
    "\n",
    "An answer to a question can be said to be \"faithful\" if the **claims** that are made in the answer **can be inferred** from the **context**.\n",
    "\n",
    "The process for quantifying this score is as follows:\n",
    "\n",
    "1. Use the following prompt with an LLM to generate shorter more focused statements provided the question and answer.\n",
    "\n",
    "    > Given a question and answer, create one\n",
    "    > or more statements from each sentence\n",
    "    > in the given answer.\n",
    "    > question: [question]\n",
    "    > answer: [answer]\n",
    "\n",
    "2. For each generated statement, verify if it can be inferred from the context with the following prompt.\n",
    "\n",
    "    > Consider the given context and following\n",
    "    > statements, then determine whether they\n",
    "    > are supported by the information present\n",
    "    > in the context. Provide a brief explanation for each statement before arriving\n",
    "    > at the verdict (Yes/No). Provide a final\n",
    "    > verdict for each statement in order at the\n",
    "    > end in the given format. Do not deviate\n",
    "    > from the specified format.\n",
    "    > statement: [statement 1]\n",
    "    > ...\n",
    "    > statement: [statement n]\n",
    "\n",
    "3. The final score can then be calculated Faithfulness = (number of supported statements) / (total number of statements)\n",
    "\n",
    "## Answer Relevance\n",
    "\n",
    "An answer can be said to be relevant if it directly addresses the question (intuitively).\n",
    "\n",
    "The process for quantifying this score is:\n",
    "\n",
    "1. Use an LLM to generate \"hypothetical\" questions to a given answer with the following prompt:\n",
    "\n",
    "    > Generate a question for the given answer.\n",
    "    > answer: [answer]\n",
    "\n",
    "2. Embed the generated \"hypothetical\" questions as vectors.\n",
    "3. Calculate the cosine similarity of the hypothetical questions and the original question, sum those similarities, and divide by n.\n",
    "\n",
    "Expressed computationally: `Answer Relevance = sum(cos_sim((q, q_i) for q_i in n)) / n`\n",
    "\n",
    "## Context Relevance\n",
    "\n",
    "\"The context is considered relevant to the extent that it exclusively contains information that is needed to answer the question.\"\n",
    "\n",
    "The process:\n",
    "\n",
    "1. Use the following LLM prompt to extract a subset of sentences necessary to answer the question. The context is defined as the formatted search result from the vector database.\n",
    "\n",
    "    > Please extract relevant sentences from\n",
    "    > the provided context that can potentially\n",
    "    > help answer the following `{question}`. If no\n",
    "    > relevant sentences are found, or if you\n",
    "    > believe the question cannot be answered\n",
    "    > from the given context, return the phrase\n",
    "    > \"Insufficient Information\". While extracting candidate sentences you’re not allowed to make any changes to sentences\n",
    "    > from given `{context}`.\n",
    "\n",
    "2. Compute the context relevance score = (number of extracted sentences) / (total number of sentences in context)\n",
    "\n",
    "# Let's start coding!\n",
    "\n",
    "If you just finished the other examples this may already be done for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import dotenv\n",
    "# mute warnings\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "warnings.filterwarnings('ignore')\n",
    "# load env vars from .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "dir_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(dir_path)\n",
    "os.environ[\"ROOT_DIR\"] = parent_directory\n",
    "\n",
    "#setting the local downloaded sentence transformer models f\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{parent_directory}/models\"\n",
    "SCHEMA_PATH = f\"{parent_directory}/2_RAG_patterns_with_redis/sec_index.yaml\"\n",
    "SOURCE_DOC = \"../resources/filings/AAPL/AAPL-2023-10k.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Redis and create chunks to populate the index"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T12:08:07.766227Z",
     "start_time": "2024-06-12T12:08:07.759763Z"
    }
   },
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:41:57 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T12:09:47.546209Z",
     "start_time": "2024-06-12T12:09:47.263330Z"
    }
   },
   "source": [
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "from redis import Redis\n",
    "\n",
    "# init Redis connection\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "\n",
    "index_name = 'langchain'\n",
    "prefix = 'chunk'\n",
    "schema = IndexSchema.from_yaml(SCHEMA_PATH)\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "\n",
    "# create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:09:47 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", cache_folder=os.getenv(\"TRANSFORMERS_CACHE\", f\"{parent_directory}/models\"))\n",
    "\n",
    "loader = UnstructuredFileLoader(SOURCE_DOC, mode=\"single\", strategy=\"fast\")\n",
    "\n",
    "# for use later with parent-doc index\n",
    "source_doc = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=0)\n",
    "chunks = loader.load_and_split(text_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_objs = [\n",
    "    {\n",
    "        \"chunk_id\": f\"{chunk.metadata['source']}-{str(uuid.uuid4())}\",\n",
    "        \"source_doc\": f\"{chunk.metadata['source']}\",\n",
    "        \"content\": chunk.page_content,\n",
    "        \"doc_type\": \"10k\",\n",
    "        \"text_embedding\": np.array(embeddings.embed_query(chunk.page_content)).astype(np.float32).tobytes()\n",
    "    }\n",
    "    for chunk in chunks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   },
   "source": [
    "keys = index.load(index_objs, id_field=\"chunk_id\")\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector store\n",
    "This is the same processes as we have done in the previous examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "# with langchain we can manually modify the default vector schema configuration\n",
    "vector_schema = {\n",
    "    \"name\": \"text_embedding\",        # name of the vector field in langchain\n",
    "    \"algorithm\": \"HNSW\",           # could use HNSW instead\n",
    "    \"dims\": 384,                   # set based on the HF model embedding dimension\n",
    "    \"distance_metric\": \"COSINE\",   # could use EUCLIDEAN or IP\n",
    "    \"datatype\": \"FLOAT32\",\n",
    "}\n",
    "\n",
    "# here we can define the entire schema spec for our index in LangChain\n",
    "index_schema = {\n",
    "    \"vector\": [vector_schema],\n",
    "    \"text\": [{\"name\": \"content\"}, {\"name\": \"source_doc\"}, {\"name\": \"doc_type\"}, {\"name\": \"chunk_id\"}],\n",
    "    \"content_vector_key\": \"text_embedding\" ,   # name of the vector field in langchain\n",
    "}\n",
    "\n",
    "\n",
    "rds = LangChainRedis.from_existing_index(\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    schema=index_schema,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out!\n",
    "We can see the vector store is populated and returning results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='In May 2023, the Company announced a new share repurchase program of up to $90 billion and raised its quarterly dividend from $0.23 to $0.24 per share beginning in May 2023. During 2023, the Company repurchased $76.6 billion of its common stock and paid dividends and dividend equivalents of $15.0 billion.\\n\\nMacroeconomic Conditions\\n\\nMacroeconomic conditions, including inﬂation, changes in interest rates, and currency ﬂuctuations, have directly and indirectly impacted, and could in the future materially impact, the Company’s results of operations and ﬁnancial condition.\\n\\nApple Inc. | 2023 Form 10-K | 20\\n\\nSegment Operating Performance\\n\\nThe following table shows net sales by reportable segment for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by reportable segment:\\n\\nAmericas Europe Greater China Japan Rest of Asia Paciﬁc\\n\\nTotal net sales\\n\\n$\\n\\n$\\n\\n162,560 94,294 72,559 24,257 29,615 383,285\\n\\n(4)% $ (1)% (2)% (7)% 1 % (3)% $\\n\\n169,658 95,118 74,200 25,977 29,375 394,328\\n\\n11 % $ 7 % 9 % (9)% 11 %\\n\\n8 % $\\n\\nAmericas\\n\\nAmericas net sales decreased 4% or $7.1 billion during 2023 compared to 2022 due to lower net sales of iPhone and Mac, partially oﬀset by higher net sales of Services.\\n\\nEurope\\n\\nEurope net sales decreased 1% or $824 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Europe net sales, which consisted primarily of lower net sales of Mac and Wearables, Home and Accessories, partially oﬀset by higher net sales of iPhone and Services.\\n\\nGreater China\\n\\nGreater China net sales decreased 2% or $1.6 billion during 2023 compared to 2022. The weakness in the renminbi relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Greater China net sales, which consisted primarily of lower net sales of Mac and iPhone.\\n\\nJapan\\n\\nJapan net sales decreased 7% or $1.7 billion during 2023 compared to 2022. The weakness in the yen relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Japan net sales, which consisted primarily of lower net sales of iPhone, Wearables, Home and Accessories and Mac.\\n\\nRest of Asia Paciﬁc', metadata={'id': 'chunk:../resources/filings/AAPL/AAPL-2023-10k.pdf-ee6fb8d1-a9d7-4bef-9ce4-9b96592cfb4d', 'source_doc': '../resources/filings/AAPL/AAPL-2023-10k.pdf', 'doc_type': '10k', 'chunk_id': '../resources/filings/AAPL/AAPL-2023-10k.pdf-ee6fb8d1-a9d7-4bef-9ce4-9b96592cfb4d'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# we will use llama3 as our local llm for this use case\n",
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    \"\"\"Create the QA chain.\"\"\"\n",
    "    from langchain.prompts import PromptTemplate\n",
    "\n",
    "    # Define our prompt\n",
    "    prompt_template = \"\"\"Use the following pieces of context from financial 10k filings data to answer the user question at the end. Only use the result from tools and evidence provided to you. If you don't know the answer, say that you don't know, don't try to make up an answer. Provide the source of the document that you used to get the answer.\n",
    "\n",
    "    This should be in the following format:\n",
    "\n",
    "    Question: [question here]\n",
    "    Answer: [answer here]\n",
    "    Source: [source document here]\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Context:\n",
    "    ---------\n",
    "    {context}\n",
    "    ---------\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def get_search_kwargs(filters, distance_threshold):\n",
    "    return {\"distance_threshold\":distance_threshold,\"filter\":filters}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=rds.as_retriever(search_type=\"similarity_distance_threshold\", search_kwargs={\"distance_threshold\":0.8, 'include_metadata': True}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have our RAG QA to test out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"What was Apple's revenue last year compared to this year??\",\n",
       " 'result': \"Based on the provided financial data, here are the answers to your question:\\n\\n**Net Sales (Total):**\\n\\n* Last year (2022): $394,328 million\\n* This year (2023): $383,285 million\\n\\nSo, Apple's revenue decreased by approximately $11.04 billion from 2022 to 2023.\\n\\n**Breakdown by Product/Service:**\\n\\n* iPhone:\\n\\t+ Last year (2022): $205,489 million\\n\\t+ This year (2023): $200,583 million\\n* Mac:\\n\\t+ Last year (2022): $29,292 million\\n\\t+ This year (2023): $28,300 million\\n* iPad:\\n\\t+ Last year (2022): $41,241 million\\n\\t+ This year (2023): $39,845 million\\n* Wearables, Home and Accessories:\\n\\t+ Last year (2022): $68,129 million\\n\\t+ This year (2023): $65,725 million (Note: I estimated this value by subtracting the change in net sales from 2022 to 2023 for these products)\\n\\nLet me know if you have any further questions!\",\n",
       " 'source_documents': [Document(page_content='In May 2023, the Company announced a new share repurchase program of up to $90 billion and raised its quarterly dividend from $0.23 to $0.24 per share beginning in May 2023. During 2023, the Company repurchased $76.6 billion of its common stock and paid dividends and dividend equivalents of $15.0 billion.\\n\\nMacroeconomic Conditions\\n\\nMacroeconomic conditions, including inﬂation, changes in interest rates, and currency ﬂuctuations, have directly and indirectly impacted, and could in the future materially impact, the Company’s results of operations and ﬁnancial condition.\\n\\nApple Inc. | 2023 Form 10-K | 20\\n\\nSegment Operating Performance\\n\\nThe following table shows net sales by reportable segment for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by reportable segment:\\n\\nAmericas Europe Greater China Japan Rest of Asia Paciﬁc\\n\\nTotal net sales\\n\\n$\\n\\n$\\n\\n162,560 94,294 72,559 24,257 29,615 383,285\\n\\n(4)% $ (1)% (2)% (7)% 1 % (3)% $\\n\\n169,658 95,118 74,200 25,977 29,375 394,328\\n\\n11 % $ 7 % 9 % (9)% 11 %\\n\\n8 % $\\n\\nAmericas\\n\\nAmericas net sales decreased 4% or $7.1 billion during 2023 compared to 2022 due to lower net sales of iPhone and Mac, partially oﬀset by higher net sales of Services.\\n\\nEurope\\n\\nEurope net sales decreased 1% or $824 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Europe net sales, which consisted primarily of lower net sales of Mac and Wearables, Home and Accessories, partially oﬀset by higher net sales of iPhone and Services.\\n\\nGreater China\\n\\nGreater China net sales decreased 2% or $1.6 billion during 2023 compared to 2022. The weakness in the renminbi relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Greater China net sales, which consisted primarily of lower net sales of Mac and iPhone.\\n\\nJapan\\n\\nJapan net sales decreased 7% or $1.7 billion during 2023 compared to 2022. The weakness in the yen relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Japan net sales, which consisted primarily of lower net sales of iPhone, Wearables, Home and Accessories and Mac.\\n\\nRest of Asia Paciﬁc', metadata={'id': 'chunk:../resources/filings/AAPL/AAPL-2023-10k.pdf-ee6fb8d1-a9d7-4bef-9ce4-9b96592cfb4d', 'source_doc': '../resources/filings/AAPL/AAPL-2023-10k.pdf', 'doc_type': '10k', 'chunk_id': '../resources/filings/AAPL/AAPL-2023-10k.pdf-ee6fb8d1-a9d7-4bef-9ce4-9b96592cfb4d'}),\n",
       "  Document(page_content='Rest of Asia Paciﬁc net sales increased 1% or $240 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar had a signiﬁcantly unfavorable year-over-year impact on Rest of Asia Paciﬁc net sales. The net sales increase consisted of higher net sales of iPhone and Services, partially oﬀset by lower net sales of Mac and iPad.\\n\\nApple Inc. | 2023 Form 10-K | 21\\n\\n2021\\n\\n153,306 89,307 68,366 28,482 26,356 365,817\\n\\nProducts and Services Performance\\n\\nThe following table shows net sales by category for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by category:\\n\\n(1)\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n$\\n\\n200,583 29,357 28,300 39,845 85,200 383,285\\n\\n(2)% $\\n\\n(27)% (3)% (3)% 9 % (3)% $\\n\\n205,489 40,177 29,292 41,241 78,129 394,328\\n\\n7 % $\\n\\n14 % (8)% 7 % 14 %\\n\\n8 % $\\n\\n(1) Products net sales include amortization of the deferred value of unspeciﬁed software upgrade rights, which are\\n\\nbundled in the sales price of the respective product.\\n\\n(2) Services net sales include amortization of the deferred value of services bundled in the sales price of certain\\n\\nproducts.\\n\\niPhone\\n\\niPhone net sales decreased 2% or $4.9 billion during 2023 compared to 2022 due to lower net sales of non-Pro iPhone models, partially oﬀset by higher net sales of Pro iPhone models.\\n\\nMac\\n\\nMac net sales decreased 27% or $10.8 billion during 2023 compared to 2022 due primarily to lower net sales of laptops.\\n\\niPad\\n\\niPad net sales decreased 3% or $1.0 billion during 2023 compared to 2022 due primarily to lower net sales of iPad mini and iPad Air, partially oﬀset by the combined net sales of iPad 9th and 10th generation.\\n\\nWearables, Home and Accessories\\n\\nWearables, Home and Accessories net sales decreased 3% or $1.4 billion during 2023 compared to 2022 due primarily to lower net sales of Wearables and Accessories.\\n\\nServices\\n\\nServices net sales increased 9% or $7.1 billion during 2023 compared to 2022 due to higher net sales across all lines of business.\\n\\nApple Inc. | 2023 Form 10-K | 22\\n\\n2021\\n\\n191,973 35,190 31,862 38,367 68,425 365,817\\n\\nGross Margin\\n\\nProducts and Services gross margin and gross margin percentage for 2023, 2022 and 2021 were as follows (dollars in millions):\\n\\n2023\\n\\n2022\\n\\nGross margin:\\n\\nProducts Services\\n\\nTotal gross margin\\n\\n$\\n\\n$\\n\\n108,803 $ 60,345 169,148 $\\n\\n114,728 $ 56,054 170,782 $\\n\\nGross margin percentage:\\n\\nProducts Services', metadata={'id': 'chunk:../resources/filings/AAPL/AAPL-2023-10k.pdf-6007d219-e03d-4602-9038-d28f160ed79f', 'source_doc': '../resources/filings/AAPL/AAPL-2023-10k.pdf', 'doc_type': '10k', 'chunk_id': '../resources/filings/AAPL/AAPL-2023-10k.pdf-6007d219-e03d-4602-9038-d28f160ed79f'}),\n",
       "  Document(page_content='Consolidated Statements of Comprehensive Income for the years ended September 30, 2023,\\n\\nSeptember 24, 2022 and September 25, 2021\\n\\nConsolidated Balance Sheets as of September 30, 2023 and September 24, 2022 Consolidated Statements of Shareholders’ Equity for the years ended September 30, 2023, September\\n\\n24, 2022 and September 25, 2021\\n\\nConsolidated Statements of Cash Flows for the years ended September 30, 2023, September 24, 2022\\n\\nand September 25, 2021\\n\\nNotes to Consolidated Financial Statements Reports of Independent Registered Public Accounting Firm\\n\\nAll ﬁnancial statement schedules have been omitted, since the required information is not applicable or is not present in amounts suﬃcient to require submission of the schedule, or because the information required is included in the consolidated ﬁnancial statements and accompanying notes.\\n\\nApple Inc. | 2023 Form 10-K | 27\\n\\nPage\\n\\n28\\n\\n29 30\\n\\n31\\n\\n32 33 49\\n\\nApple Inc.\\n\\nCONSOLIDATED STATEMENTS OF OPERATIONS (In millions, except number of shares, which are reﬂected in thousands, and per-share amounts)\\n\\nYears ended\\n\\nSeptember 30, 2023\\n\\nSeptember 24, 2022\\n\\nSeptember 25, 2021\\n\\nNet sales: Products Services\\n\\nTotal net sales\\n\\n$\\n\\n298,085 $ 85,200 383,285\\n\\n316,199 $ 78,129 394,328\\n\\n297,392 68,425 365,817\\n\\nCost of sales: Products Services\\n\\nTotal cost of sales Gross margin\\n\\n189,282 24,855 214,137 169,148\\n\\n201,471 22,075 223,546 170,782\\n\\n192,266 20,715 212,981 152,836\\n\\nOperating expenses:\\n\\nResearch and development Selling, general and administrative\\n\\nTotal operating expenses\\n\\n29,915 24,932 54,847\\n\\n26,251 25,094 51,345\\n\\n21,914 21,973 43,887\\n\\nOperating income Other income/(expense), net Income before provision for income taxes Provision for income taxes Net income\\n\\n$\\n\\n114,301 (565) 113,736 16,741 96,995 $\\n\\n119,437 (334) 119,103 19,300 99,803 $\\n\\n108,949 258 109,207 14,527 94,680\\n\\nEarnings per share:\\n\\nBasic Diluted\\n\\n$ $\\n\\n6.16 $ 6.13 $\\n\\n6.15 $ 6.11 $\\n\\n5.67 5.61\\n\\nShares used in computing earnings per share:\\n\\nBasic Diluted\\n\\n15,744,231 15,812,547\\n\\n16,215,963 16,325,819\\n\\n16,701,272 16,864,919\\n\\nSee accompanying Notes to Consolidated Financial Statements.\\n\\nApple Inc. | 2023 Form 10-K | 28\\n\\nApple Inc.\\n\\nCONSOLIDATED STATEMENTS OF COMPREHENSIVE INCOME (In millions)\\n\\nYears ended\\n\\nSeptember 30, 2023\\n\\nSeptember 24, 2022\\n\\nSeptember 25, 2021\\n\\nNet income Other comprehensive income/(loss):\\n\\n$\\n\\n96,995 $\\n\\n99,803 $\\n\\n94,680\\n\\nChange in foreign currency translation, net of tax\\n\\n(765)\\n\\n(1,511)\\n\\n501', metadata={'id': 'chunk:../resources/filings/AAPL/AAPL-2023-10k.pdf-042b3c7b-6abb-4612-8c5d-3330964026c3', 'source_doc': '../resources/filings/AAPL/AAPL-2023-10k.pdf', 'doc_type': '10k', 'chunk_id': '../resources/filings/AAPL/AAPL-2023-10k.pdf-042b3c7b-6abb-4612-8c5d-3330964026c3'}),\n",
       "  Document(page_content='For the sale of third-party products where the Company obtains control of the product before transferring it to the customer, the Company recognizes revenue based on the gross amount billed to customers. The Company considers multiple factors when determining whether it obtains control of third-party products, including evaluating if it can establish the price of the product, retains inventory risk for tangible products or has the responsibility for ensuring acceptability of the product. For third-party applications sold through the App Store, the Company does not obtain control of the product before transferring it to the customer. Therefore, the Company accounts for all third- party application–related sales on a net basis by recognizing in Services net sales only the commission it retains.\\n\\nApple Inc. | 2023 Form 10-K | 34\\n\\nNet sales disaggregated by signiﬁcant products and services for 2023, 2022 and 2021 were as follows (in millions):\\n\\n2023\\n\\n2022\\n\\n2021\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n$\\n\\n200,583 $ 29,357 28,300 39,845 85,200 383,285 $\\n\\n205,489 $ 40,177 29,292 41,241 78,129 394,328 $\\n\\n191,973 35,190 31,862 38,367 68,425 365,817\\n\\n(1) Products net sales include amortization of the deferred value of unspeciﬁed software upgrade rights, which are\\n\\nbundled in the sales price of the respective product.\\n\\n(2) Services net sales include amortization of the deferred value of services bundled in the sales price of certain\\n\\nproducts.\\n\\nTotal net sales include $8.2 billion of revenue recognized in 2023 that was included in deferred revenue as of September 24, 2022, $7.5 billion of revenue recognized in 2022 that was included in deferred revenue as of September 25, 2021, and $6.7 billion of revenue recognized in 2021 that was included in deferred revenue as of September 26, 2020.\\n\\nThe Company’s proportion of net sales by disaggregated revenue source was generally consistent for each reportable segment in Note 13, “Segment Information and Geographic Data” for 2023, 2022 and 2021, except in Greater China, where iPhone revenue represented a moderately higher proportion of net sales.', metadata={'id': 'chunk:../resources/filings/AAPL/AAPL-2023-10k.pdf-c146a1e8-998c-4285-804d-24ad5a41ba6f', 'source_doc': '../resources/filings/AAPL/AAPL-2023-10k.pdf', 'doc_type': '10k', 'chunk_id': '../resources/filings/AAPL/AAPL-2023-10k.pdf-c146a1e8-998c-4285-804d-24ad5a41ba6f'})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What was Apple's revenue last year compared to this year??\"\n",
    "res=qa(query)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup complete!\n",
    "\n",
    "We will use the TestsetGenerator class from RAGAS to create some questions to evaluate our RAG application with. For demo speed sake, these have been pre-loadeded into a json but the code for generation is shown afterwards if you are interested in generating for your own use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What services does Apple offer through its Payment Services, and how do these services contribute to the company's overall sales?\",\n",
       " \"What is the estimated maximum one-day loss in fair value of the Company's foreign currency derivative positions, according to the VAR model as of September 24, 2022?\",\n",
       " \"What drives Apple Inc.'s competitive edge & how does it impact results & financials?\",\n",
       " \"What are potential risks for Apple if it doesn't meet regulatory expectations or faces antitrust scrutiny, given its ESG investments & reliance on 3rd party data?\",\n",
       " \"What factors contributed to the 7% boost in iPhone sales and how did this growth align with Apple's recent product launches and industry developments?\",\n",
       " \"What were the primary factors driving the increase in Americas' net sales in 2022 compared to 2021?\",\n",
       " \"What impact do new product and service introductions have on Apple's net sales, cost of sales, and operating expenses?\",\n",
       " \"What are the main characteristics of the Company's manufacturing purchase obligations as of September 24, 2022?\",\n",
       " \"What is the trading symbol for Apple Inc.'s common stock?\",\n",
       " \"What is the estimated maximum one-day loss in fair value of the Company's foreign currency derivative positions as of September 24, 2022?\",\n",
       " 'What are the potential consequences if Apple Inc. fails to obtain licenses for third-party intellectual property or uses such intellectual property on unreasonable terms?',\n",
       " 'What role does the company culture play in its ability to recruit and retain highly skilled employees, and how might it impact the business if not managed effectively?',\n",
       " 'What drove iPhone net sales growth in 2022, considering Q4 2021 saw new models released?',\n",
       " \"What OS choices support Apple's diverse product lineup?\",\n",
       " \"What drives changes in Apple's effective tax rates, and how do factors like earnings mix, statutory tax rates, and tax laws influence these fluctuations?\",\n",
       " \"What could go awry for Apple's top-grossing item, leading to a hit on Q2 earnings?\",\n",
       " \"What obstacles might affect the Company's DRM & security solution progress, potentially straining ties with tech partners?\",\n",
       " \"How might Apple's performance be impacted if economic headwinds intensify, driving up competition & eroding consumer trust?\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"resources/questions.json\", \"r\") as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilize TestSetGenerator from ragas to generate test questions\n",
    "\n",
    "This can be a time consuming process so we have gone ahead and pregenerated this with the following code. See more on creating test sets [here](https://docs.ragas.io/en/latest/getstarted/testset_generation.html).\n",
    "\n",
    "Note: while we are using synthetic test set here RAGAS can be utilized with human labeled data and [self created test sets](https://docs.ragas.io/en/stable/howtos/applications/data_preparation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if problems with nltk data\n",
    "# import os\n",
    "# os.environ[\"NLTK_DATA\"] = '/Users/<user>/nltk_data'\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "generator_llm = Ollama(model=\"llama3\")\n",
    "critic_llm = Ollama(model=\"llama3\")\n",
    "embeddings = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "generator = TestsetGenerator.from_llama_index(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[SOURCE_DOC])\n",
    "\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = generator.generate_with_llamaindex_docs(\n",
    "    documents,\n",
    "    test_size=20,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")\n",
    "\n",
    "testset.to_pandas().to_csv(\"gen_testset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for evaluating QA chain\n",
    "\n",
    "In the following code we take a list of questions and a QA retrieval chain as input. We call the chain and store the answer returned along with the context (aka source documents) to be used as the essential data for our evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define reusable helper function for evaluating our test set against different chains\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_relevancy,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "def parse_contexts(source_docs):\n",
    "    return [doc.page_content for doc in source_docs]\n",
    "\n",
    "def create_evaluation_dataset(chain, questions):\n",
    "    res_set = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "    }\n",
    "\n",
    "    for question in questions:\n",
    "        # call QA chain\n",
    "        result = chain.invoke(question)\n",
    "\n",
    "        res_set[\"question\"].append(question)\n",
    "        res_set[\"answer\"].append(result[\"result\"])\n",
    "        res_set[\"contexts\"].append(parse_contexts(result[\"source_documents\"]))\n",
    "    return Dataset.from_dict(res_set)\n",
    "\n",
    "def evaluate_chain(chain, questions, test_name):\n",
    "    eval_dataset = create_evaluation_dataset(chain, questions)\n",
    "\n",
    "    eval_result = evaluate(\n",
    "        eval_dataset,\n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_relevancy\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    eval_df = eval_result.to_pandas()\n",
    "    # store the results of our test for future reference in csv\n",
    "    eval_df.to_csv(f\"{test_name}.csv\")\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c86de868624488be41cfe827b9c05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "# by default ragas evaluation uses OpenAI\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")\n",
    "\n",
    "basic_rag_test = evaluate_chain(qa, questions, \"basic_rag_ragas_testset_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.765520</td>\n",
       "      <td>0.650937</td>\n",
       "      <td>0.017481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.284628</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.013191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.951826</td>\n",
       "      <td>0.011685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     18.000000         18.000000          18.000000\n",
       "mean       0.765520          0.650937           0.017481\n",
       "std        0.284628          0.474443           0.013191\n",
       "min        0.166667          0.000000           0.004926\n",
       "25%        0.625000          0.000000           0.007412\n",
       "50%        0.853571          0.951826           0.011685\n",
       "75%        1.000000          1.000000           0.024734\n",
       "max        1.000000          1.000000           0.044444"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rag_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "We can see from the above results that our basic RAG did okay but not necessarily great. This is okay because now that we have a baseline for the performance of our RAG, we can begin to try different techniques to improve our results. The reason it is so important to have a framework in place for evaluation is now we can properly experiment with different techniques to see what improves our particular system.\n",
    "\n",
    "One technique we could try is to implement a parent document retriever. A parent document retriever attempts to optimize two competing objectives within RAG - 1) smaller chunks can lead to better embeddings since there is less context to lose the point (so to speak) 2) larger chunks help retain what could be valuable overall context to retrieval. Parent document retrieval allows for the initial query search on smaller chunks for specificity but returns the larger chunks for more complete context. \n",
    "\n",
    "Let's perform an experiment to see if this technique improves our metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import TextLoader, UnstructuredFileLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.redis import Redis as LangChainRedis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will make a new index for this example defined directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "PARENT_CHUNK_SIZE = 5000\n",
    "CHILD_CHUNK_SIZE = 400\n",
    "\n",
    "# This text splitter is used to create the parent documents aka larger chunks\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=PARENT_CHUNK_SIZE)\n",
    "\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=CHILD_CHUNK_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings for redis vector store\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it is **critical** that our index includes the `doc_id` field otherwise the parent document linking will not happen correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "# with langchain we can manually modify the default vector schema configuration\n",
    "vector_schema = {\n",
    "    \"name\": \"chunk_vector\",        # name of the vector field in langchain\n",
    "    \"algorithm\": \"HNSW\",           # could use HNSW instead\n",
    "    \"dims\": 384,                   # set based on the HF model embedding dimension\n",
    "    \"distance_metric\": \"COSINE\",   # could use EUCLIDEAN or IP\n",
    "    \"datatype\": \"FLOAT32\",\n",
    "}\n",
    "\n",
    "# here we can define the entire schema spec for our index in LangChain\n",
    "index_schema = {\n",
    "    \"vector\": [vector_schema],\n",
    "    \"text\": [{\"name\": \"content\"}, {\"name\": \"doc_id\"}],\n",
    "    \"content_vector_key\": \"chunk_vector\" ,   # name of the vector field in langchain\n",
    "}\n",
    "\n",
    "vector_store = LangChainRedis(\n",
    "    REDIS_URL,\n",
    "    \"child_docs\",\n",
    "    embeddings,\n",
    "    index_schema=index_schema\n",
    ")\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "parent_doc_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we are adding the source documents and the ParentDocumentRetriever will automatically split them into parent and child documents\n",
    "parent_doc_retriever.add_documents(source_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Fiscal Period\\n\\nThe Company’s ﬁscal year is the 52- or 53-week period that ends on the last Saturday of September. An additional week is included in the ﬁrst ﬁscal quarter every ﬁve or six years to realign the Company’s ﬁscal quarters with calendar quarters, which occurred in the ﬁrst quarter of 2023. The Company’s ﬁscal year 2023 spanned 53 weeks, whereas ﬁscal years 2022 and 2021 spanned 52 weeks each.\\n\\nFiscal Year Highlights\\n\\nThe Company’s total net sales were $383.3 billion and net income was $97.0 billion during 2023.\\n\\nThe Company’s total net sales decreased 3% or $11.0 billion during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in total net sales, which consisted primarily of lower net sales of Mac and iPhone, partially oﬀset by higher net sales of Services.\\n\\nThe Company announces new product, service and software oﬀerings at various times during the year. Signiﬁcant announcements during ﬁscal year 2023 included the following:\\n\\nFirst Quarter 2023:\\n\\n• • MLS Season Pass, a Major League Soccer subscription streaming service.\\n\\niPad and iPad Pro; Next-generation Apple TV 4K; and\\n\\nSecond Quarter 2023:\\n\\nMacBook Pro 14”, MacBook Pro 16” and Mac mini; and • Second-generation HomePod.\\n\\nThird Quarter 2023:\\n\\nMacBook Air 15”, Mac Studio and Mac Pro; •\\n\\nApple Vision Pro™, the Company’s ﬁrst spatial computer featuring its new visionOS™, expected to be available in early calendar year 2024; and iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10, updates to the Company’s operating systems.\\n\\n\\n\\nFourth Quarter 2023:\\n\\n•\\n\\niPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max; and Apple Watch Series 9 and Apple Watch Ultra 2.\\n\\nIn May 2023, the Company announced a new share repurchase program of up to $90 billion and raised its quarterly dividend from $0.23 to $0.24 per share beginning in May 2023. During 2023, the Company repurchased $76.6 billion of its common stock and paid dividends and dividend equivalents of $15.0 billion.\\n\\nMacroeconomic Conditions\\n\\nMacroeconomic conditions, including inﬂation, changes in interest rates, and currency ﬂuctuations, have directly and indirectly impacted, and could in the future materially impact, the Company’s results of operations and ﬁnancial condition.\\n\\nApple Inc. | 2023 Form 10-K | 20\\n\\nSegment Operating Performance\\n\\nThe following table shows net sales by reportable segment for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by reportable segment:\\n\\nAmericas Europe Greater China Japan Rest of Asia Paciﬁc\\n\\nTotal net sales\\n\\n$\\n\\n$\\n\\n162,560 94,294 72,559 24,257 29,615 383,285\\n\\n(4)% $ (1)% (2)% (7)% 1 % (3)% $\\n\\n169,658 95,118 74,200 25,977 29,375 394,328\\n\\n11 % $ 7 % 9 % (9)% 11 %\\n\\n8 % $\\n\\nAmericas\\n\\nAmericas net sales decreased 4% or $7.1 billion during 2023 compared to 2022 due to lower net sales of iPhone and Mac, partially oﬀset by higher net sales of Services.\\n\\nEurope\\n\\nEurope net sales decreased 1% or $824 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Europe net sales, which consisted primarily of lower net sales of Mac and Wearables, Home and Accessories, partially oﬀset by higher net sales of iPhone and Services.\\n\\nGreater China\\n\\nGreater China net sales decreased 2% or $1.6 billion during 2023 compared to 2022. The weakness in the renminbi relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Greater China net sales, which consisted primarily of lower net sales of Mac and iPhone.\\n\\nJapan\\n\\nJapan net sales decreased 7% or $1.7 billion during 2023 compared to 2022. The weakness in the yen relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Japan net sales, which consisted primarily of lower net sales of iPhone, Wearables, Home and Accessories and Mac.\\n\\nRest of Asia Paciﬁc\\n\\nRest of Asia Paciﬁc net sales increased 1% or $240 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar had a signiﬁcantly unfavorable year-over-year impact on Rest of Asia Paciﬁc net sales. The net sales increase consisted of higher net sales of iPhone and Services, partially oﬀset by lower net sales of Mac and iPad.\\n\\nApple Inc. | 2023 Form 10-K | 21\\n\\n2021\\n\\n153,306 89,307 68,366 28,482 26,356 365,817\\n\\nProducts and Services Performance\\n\\nThe following table shows net sales by category for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by category:\\n\\n(1)\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n$\\n\\n200,583 29,357 28,300 39,845 85,200 383,285\\n\\n(2)% $\\n\\n(27)% (3)% (3)% 9 % (3)% $\\n\\n205,489 40,177 29,292 41,241 78,129 394,328\\n\\n7 % $\\n\\n14 % (8)% 7 % 14 %\\n\\n8 % $', metadata={'source': '../resources/filings/AAPL/AAPL-2023-10k.pdf'})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test that the retirever works\n",
    "retrieved_docs = parent_doc_retriever.invoke(\"apples's revenue 2023\")\n",
    "retrieved_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the same but use our new retriever\n",
    "parent_doc_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=parent_doc_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": get_prompt()},\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d53ae043b24f4897bbe8a16d844e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n"
     ]
    }
   ],
   "source": [
    "parent_doc_test = evaluate_chain(parent_doc_qa, questions, \"parent_doc_ragas_testset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.629412</td>\n",
       "      <td>0.721332</td>\n",
       "      <td>0.040463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.423590</td>\n",
       "      <td>0.460336</td>\n",
       "      <td>0.050384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245994</td>\n",
       "      <td>0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       faithfulness  answer_relevancy  context_relevancy\n",
       "count     17.000000         18.000000          18.000000\n",
       "mean       0.629412          0.721332           0.040463\n",
       "std        0.423590          0.460336           0.050384\n",
       "min        0.000000          0.000000           0.008547\n",
       "25%        0.333333          0.245994           0.011905\n",
       "50%        0.800000          1.000000           0.013699\n",
       "75%        1.000000          1.000000           0.051478\n",
       "max        1.000000          1.000000           0.166667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_doc_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "It appears that implementing the parent doc retriever improved the answer and context relevancy of our system but had a negative impact on faithfulness. For a more complete analysis we would want to perform these tests with a much larger dataset to ensure statistical relevance but now we have an idea of how these tests can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "As a review, in this notebook we covered:\n",
    "- why it's important to have an evaluation framework\n",
    "- the basic theory of RAGAS\n",
    "- how to interpret and generate faithfulness, answer_relevancy, and context_relevancy\n",
    "- code to evaluate two different RAG chains to monitor how using a parent document retriever might improve our results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
